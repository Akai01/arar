{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c8d8c2b-63b4-4976-96d4-6da83a3114c2",
   "metadata": {},
   "source": [
    "\\subsection{The ARAR algorithm}\n",
    "\\subsubsection{Memory Shortening}\n",
    "The ARAR algorithm applies a memory-shortening transformation if the underlying process of a given time series ${Y_{t}, t = 1, 2, ..., n}$ is \"long-memory\" then it fits an autoregressive model. \n",
    "\n",
    "The algorithm follows five steps to classify ${Y_{t}}$ and take one of the following three actions:\n",
    "\n",
    "\\begin{itemize}\n",
    "    \\item L: declare ${Y_{t}}$ as long memory and form  ${Y_{t}}$ by ${\\tilde{Y}_{t} = Y_{t} - \\hat{\\phi}Y_{t - \\hat{\\tau}}}$\n",
    "     \\item M: declare ${Y_{t}}$ as moderately long memory and form  ${Y_{t}}$ by ${\\tilde{Y}_{t} = Y_{t} - \\hat{\\phi}_{1}Y_{t -1} - \\hat{\\phi}_{2}Y_{t -2}}$\n",
    "     \\item S: declare ${Y_{t}}$ as short memory.\n",
    "\\end{itemize}\n",
    "\n",
    "\\par If ${Y_{t}}$ declared to be $L$ or $M$ then the series ${Y_{t}}$ is transformed again until. The transformation process continuous until the transformed series is classified as short memory. However, the maximum number of transformation process is three, it is very rare a time series require more than 2 \\cite{ITSM}.\n",
    "\n",
    "The algorithm\n",
    "\\begin{itemize}\n",
    "    \\item[1] For each $\\tau = 1, 2, ..., 15$, we find the value $\\hat{\\phi(\\tau)}$ of \\hat{\\phi} that minimizes \n",
    "    \n",
    "   $ ERR(\\phi, \\tau) = \\frac{\\sum_{t=\\tau +1 }^{n} [Y_{t} - \\phi Y_{t-\\tau}]^2 }{\\sum_{t=\\tau +1 }^{n} Y_{t}^{2}} $ then define \n",
    "   $Err(\\tau) = ERR(\\hat{\\phi(\\tau), \\tau})$ and choose the lag $\\hat{\\tau}$ to be the value of $\\tau$ that minimizes  $Err(\\tau)$.\n",
    "   \\item[2] If $Err(\\hat{\\tau}) \\leq  8/n $,  ${Y_{t}}$ is a long-memory series.\n",
    "   \\item[3] If $\\hat{\\phi}( \\hat{\\tau} ) \\geq 0.93$ and $\\hat{\\tau} > 2$,  ${Y_{t}}$ is a long-memory series.\n",
    "   \\item[4] If $\\hat{\\phi}( \\hat{\\tau} ) \\geq 0.93$ and $\\hat{\\tau} = 1$ or $2$, ${Y_{t}}$ is a long-memory series.\n",
    "   \\item[5] If $\\hat{\\phi}( \\hat{\\tau} ) < 0.93$, ${Y_{t}}$ is a short-memory series\n",
    "\\end{itemize}\n",
    "\n",
    "\\subsubsection{Subset Autoregressive Model}\n",
    "In the following we will describe how ARAR algorithm fits an autoregressive process to the mean-corrected series $X_{t} = S_{t}- {\\Bar{S}}$, $t = k+1, ..., n$ where ${S_{t}, t = k + 1, ..., n}$ is the memory-shortened version of  ${Y_{t}}$ which derived from the five steps we described above and $\\Bar{S}$ is the sample mean of $S_{k+1}, ..., S_{n}$.\n",
    "\n",
    "The fitted model has the following form:\n",
    "\n",
    "$X_{t} = \\phi_{1}X{t-1} + \\phi_{1}X_{t-l_{1}} + \\phi_{1}X_{t- l_{1}} + \\phi_{1}X_{t-l_{1}} + Z $\n",
    "\n",
    "where $Z \\sim WN(0, \\sigma^{2})$. The coefficients $\\phi_{j}$ and white noise variance $\\sigma^2$ can be derived from the Yule-Walker equations for given lags $l_1, l_2,$ and $l_3$ :\n",
    "\n",
    " \\begin{bmatrix}\n",
    "1 & \\hat{\\rho}(l_1 - 1) & \\hat{\\rho}(l_2 - 1) & \\hat{\\rho}(l_3 - 1)\\\\\n",
    "\\hat{\\rho}(l_1 - 1) &1 & \\hat{\\rho}(l_2 - l_1) & \\hat{\\rho}(l_3 - l_1)\\\\\n",
    "\\hat{\\rho}(l_2 - 1) & \\hat{\\rho}(l_2 - l_1) & 1 & \\hat{\\rho}(l_2 - l_2)\\\\\n",
    "\\hat{\\rho}(l_3 - 1) & \\hat{\\rho}(l_3 - l_1) & \\hat{\\rho}(l_3 - l_1) & 1\n",
    "\\end{bmatrix}   \\begin{bmatrix}\n",
    "\\phi_{1} \\\\\n",
    "\\phi_{l_1} \\\\\n",
    "\\phi_{l_2}\\\\\n",
    "\\phi_{l_3}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "\\hat{\\rho}(1) \\\\\n",
    "\\hat{\\rho}(l_1) \\\\\n",
    "\\hat{\\rho}(l_2)\\\\\n",
    "\\hat{\\rho}(l_3)\n",
    "\\end{bmatrix}\n",
    "\n",
    "\\\\ and $\\sigma^2 = \\hat{\\gamma}(0) [1-\\phi_1\\hat{\\rho}(1)] - \\phi_{l_1}\\hat{\\rho}(l_1)] - \\phi_{l_2}\\hat{\\rho}(l_2)] - \\phi_{l_3}\\hat{\\rho}(l_3)]$, where $\\hat{\\gamma}(j)$ and $\\hat{\\rho}(j), j = 0, 1, 2, ...,$ are the sample autocovariances and autocorelations of the series $X_{t}$. \n",
    "\n",
    "The algorithm computes the coefficients of $\\phi(j)$ for each set of lags where\n",
    "$1<l_1<l_2<l_3 \\leq m $ where m chosen to be 13 or 26. The algorithm selects the model that the Yule-Walker estimate of $\\sigma^2$ is minimal.\n",
    "\n",
    "\\subsubsection{Forecasting}\n",
    "\n",
    "If short-memory filter found in first step it has coefficients $\\Psi_0, \\Psi_1, ..., \\Psi_k (k \\geq0)$ where $\\Psi_0 = 1$. In this case the transforemed series can be expressed as \n",
    "\\begin{equation}\n",
    "    S_t = \\Psi(B)Y_t = Y_t + \\Psi_1 Y_{t-1} + ...+ \\Psi_k Y_{t-k},\n",
    "\\end{equation}\n",
    "where $\\Psi(B) = 1 + \\Psi_1B + ...+ \\Psi_k B^k$ is polynomial in the back-shift operator.\n",
    "\n",
    "If the coefficients of the subset autoregression found in the second step it has coefficients $\\phi_1, \\phi_{l_1},  \\phi_{l_2}$ and $\\phi_{l_3}$ then the subset AR model for $X_t = S_t - \\Bar{S}$ is\n",
    "\\begin{equation}\n",
    "    \\phi(B)X_t = Z_t,\n",
    "\\end{equation}\n",
    "\n",
    "where $Z_t$ is a white-noise series with zero mean and constant variance and $\\phi(B) = 1 - \\phi_1B - \\phi_{l_1}B^{l_1} - \\phi_{l_2}B^{l_2} - \\phi_{l_3}B^{l_3}$. From equation (1) and (2) one can obtain\n",
    "\n",
    "\\begin{equation}\n",
    "    \\xi(B)Y_t = \\phi(1)\\Bar{S} + Z_t,\n",
    "\\end{equation}\n",
    "where $\\xi (B) = \\Psi(B)\\phi(B)$.\n",
    "\n",
    "Assuming the fitted model in equation (3) is an appropriate model, and $Z_t$ is uncorrelated with $Y_j, j <t$ $\\forall t \\in T$, one can determine minimum mean squared error linear predictors $P_n Y_{n + h}$ of $Y_{n+h}$ in terms of ${1, Y_1, ..., Y_n}$ for $n > k + l_3$, from recursions\n",
    "\n",
    "\\begin{equation}\n",
    "    P_n Y_{n+h} = - \\sum_{j = 1}^{k + l_3} \\xiP_nY_{n+h-j} + \\phi(1)\\Bar{S},  h\\geq 1,\n",
    "\\end{equation}\n",
    "with the initial conditions $P_n Y_{n+h} = Y_{n + h},$ for $h\\leq0.$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

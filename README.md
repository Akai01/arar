# The ARAR Algorithm:

![formula](https://render.githubusercontent.com/render/math?math=##%20Memory%20Shortening%20The%20ARAR%20algorithm%20applies%20a%20memory-shortening%20transformation%20if%20the%20underlying%20process%20of%20a%20given%20time%20series%20${Y_{t},%20t%20=%201,%202,%20...,%20n}$%20is%20"long-memory"%20then%20it%20fits%20an%20autoregressive%20model.%20The%20algorithm%20follows%20five%20steps%20to%20classify%20${Y_{t}}$%20and%20take%20one%20of%20the%20following%20three%20actions:%20*%20L:%20declare%20${Y_{t}}$%20as%20long%20memory%20and%20form%20${Y_{t}}$%20by%20${\tilde{Y}_{t}%20=%20Y_{t}%20-%20\hat{\phi}Y_{t%20-%20\hat{\tau}}}$%20*%20M:%20declare%20${Y_{t}}$%20as%20moderately%20long%20memory%20and%20form%20${Y_{t}}$%20by%20${\tilde{Y}_{t}%20=%20Y_{t}%20-%20\hat{\phi}_{1}Y_{t%20-1}%20-%20\hat{\phi}_{2}Y_{t%20-2}}$%20*%20S:%20declare%20${Y_{t}}$%20as%20short%20memory.%20\par%20If%20${Y_{t}}$%20declared%20to%20be%20$L$%20or%20$M$%20then%20the%20series%20${Y_{t}}$%20is%20transformed%20again%20until.%20The%20transformation%20process%20continuous%20until%20the%20transformed%20series%20is%20classified%20as%20short%20memory.%20However,%20the%20maximum%20number%20of%20transformation%20process%20is%20three,%20it%20is%20very%20rare%20a%20time%20series%20require%20more%20than%202.%20##%20The%20Algorithm:%20*%201.%20For%20each%20$\tau%20=%201,%202,%20...,%2015$,%20we%20find%20the%20value%20$\hat{\phi(\tau)}%20$%20of%20$\hat{\phi}$%20that%20minimizes%20$ERR(\phi,%20\tau)%20=%20\frac{\sum_{t=\tau%20%2B1%20}^{n}%20[Y_{t}%20-%20\phi%20Y_{t-\tau}]^2%20}{\sum_{t=\tau%20%2B1%20}^{n}%20Y_{t}^{2}}$%20then%20define%20$Err(\tau)%20=%20ERR(\hat{\phi(\tau),%20\tau})$%20and%20choose%20the%20lag%20$\hat{\tau}$%20to%20be%20the%20value%20of%20$\tau$%20that%20minimizes%20$Err(\tau)$.%20*%202.%20If%20$Err(\hat{\tau})%20\leq%208/n$,%20${Y_{t}}$%20is%20a%20long-memory%20series.%20*%203.%20If%20$\hat{\phi}(%20\hat{\tau}%20)%20\geq%200.93$%20and%20$\hat{\tau}%20>%202$,%20${Y_{t}}$%20is%20a%20long-memory%20series.%20*%204.%20If%20$\hat{\phi}(%20\hat{\tau}%20)%20\geq%200.93$%20and%20$\hat{\tau}%20=%201$%20or%20$2$,%20${Y_{t}}$%20is%20a%20long-memory%20series.%20*%205.%20If%20$\hat{\phi}(%20\hat{\tau}%20)%20<%200.93$,%20${Y_{t}}$%20is%20a%20short-memory%20series.%20##%20Subset%20Autoregressive%20Model:%20In%20the%20following%20we%20will%20describe%20how%20ARAR%20algorithm%20fits%20an%20autoregressive%20process%20to%20the%20mean-corrected%20series%20$X_{t}%20=%20S_{t}-%20{\bar{S}}$,%20$t%20=%20k%2B1,%20...,%20n$%20where%20${S_{t},%20t%20=%20k%20%2B%201,%20...,%20n}$%20is%20the%20memory-shortened%20version%20of%20${Y_{t}}$%20which%20derived%20from%20the%20five%20steps%20we%20described%20above%20and%20$\bar{S}$%20is%20the%20sample%20mean%20of%20$S_{k%2B1},%20...,%20S_{n}$.%20The%20fitted%20model%20has%20the%20following%20form:%20$X_{t}%20=%20\phi_{1}X{t-1}%20%2B%20\phi_{1}X_{t-l_{1}}%20%2B%20\phi_{1}X_{t-%20l_{1}}%20%2B%20\phi_{1}X_{t-l_{1}}%20%2B%20Z$%20where%20$Z%20\sim%20WN(0,%20\sigma^{2})$.%20The%20coefficients%20$\phi_{j}$%20and%20white%20noise%20variance%20$\sigma^2$%20can%20be%20derived%20from%20the%20Yule-Walker%20equations%20for%20given%20lags%20$l_1,%20l_2,$%20and%20$l_3$%20:%20\begin{equation}%20\begin{bmatrix}%201%20%26%20\hat{\rho}(l_1%20-%201)%20%26%20\hat{\rho}(l_2%20-%201)%20%26%20\hat{\rho}(l_3%20-%201)\\%20\hat{\rho}(l_1%20-%201)%20%261%20%26%20\hat{\rho}(l_2%20-%20l_1)%20%26%20\hat{\rho}(l_3%20-%20l_1)\\%20\hat{\rho}(l_2%20-%201)%20%26%20\hat{\rho}(l_2%20-%20l_1)%20%26%201%20%26%20\hat{\rho}(l_2%20-%20l_2)\\%20\hat{\rho}(l_3%20-%201)%20%26%20\hat{\rho}(l_3%20-%20l_1)%20%26%20\hat{\rho}(l_3%20-%20l_1)%20%26%201%20\end{bmatrix}*\begin{bmatrix}%20\phi_{1}%20\\%20\phi_{l_1}%20\\%20\phi_{l_2}\\%20\phi_{l_3}%20\end{bmatrix}%20=%20\begin{bmatrix}%20\hat{\rho}(1)%20\\%20\hat{\rho}(l_1)%20\\%20\hat{\rho}(l_2)\\%20\hat{\rho}(l_3)%20\end{bmatrix}%20\end{equation}%20and%20$\sigma^2%20=%20\hat{\gamma}(0)%20[1-\phi_1\hat{\rho}(1)]%20-%20\phi_{l_1}\hat{\rho}(l_1)]%20-%20\phi_{l_2}\hat{\rho}(l_2)]%20-%20\phi_{l_3}\hat{\rho}(l_3)]$,%20where%20$\hat{\gamma}(j)$%20and%20$\hat{\rho}(j),%20j%20=%200,%201,%202,%20...,$%20are%20the%20sample%20autocovariances%20and%20autocorelations%20of%20the%20series%20$X_{t}$.%20The%20algorithm%20computes%20the%20coefficients%20of%20$\phi(j)$%20for%20each%20set%20of%20lags%20where%20$1<l_1<l_2<l_3%20\leq%20m$%20where%20m%20chosen%20to%20be%2013%20or%2026.%20The%20algorithm%20selects%20the%20model%20that%20the%20Yule-Walker%20estimate%20of%20$\sigma^2$%20is%20minimal.%20##%20Forecasting%20If%20short-memory%20filter%20found%20in%20first%20step%20it%20has%20coefficients%20$\Psi_0,%20\Psi_1,%20...,%20\Psi_k%20(k%20\geq0)$%20where%20$\Psi_0%20=%201$.%20In%20this%20case%20the%20transforemed%20series%20can%20be%20expressed%20as%20\begin{equation}%20S_t%20=%20\Psi(B)Y_t%20=%20Y_t%20%2B%20\Psi_1%20Y_{t-1}%20%2B%20...%2B%20\Psi_k%20Y_{t-k},%20\end{equation}%20where%20$\Psi(B)%20=%201%20%2B%20\Psi_1B%20%2B%20...%2B%20\Psi_k%20B^k$%20is%20polynomial%20in%20the%20back-shift%20operator.%20If%20the%20coefficients%20of%20the%20subset%20autoregression%20found%20in%20the%20second%20step%20it%20has%20coefficients%20$\phi_1,%20\phi_{l_1},%20\phi_{l_2}$%20and%20$\phi_{l_3}$%20then%20the%20subset%20AR%20model%20for%20$X_t%20=%20S_t%20-%20\bar{S}$%20is%20\begin{equation}%20\phi(B)X_t%20=%20Z_t,%20\end{equation}%20where%20$Z_t$%20is%20a%20white-noise%20series%20with%20zero%20mean%20and%20constant%20variance%20and%20$\phi(B)%20=%201%20-%20\phi_1B%20-%20\phi_{l_1}B^{l_1}%20-%20\phi_{l_2}B^{l_2}%20-%20\phi_{l_3}B^{l_3}$.%20From%20equation%20(1)%20and%20(2)%20one%20can%20obtain%20\begin{equation}%20\xi(B)Y_t%20=%20\phi(1)\bar{S}%20%2B%20Z_t,%20\end{equation}%20where%20$\xi%20(B)%20=%20\Psi(B)\phi(B)$.%20Assuming%20the%20fitted%20model%20in%20equation%20(3)%20is%20an%20appropriate%20model,%20and%20$Z_t$%20is%20uncorrelated%20with%20$Y_j,%20j%20<t$%20$\forall%20t%20\in%20T$,%20one%20can%20determine%20minimum%20mean%20squared%20error%20linear%20predictors%20$P_n%20Y_{n%20%2B%20h}$%20of%20$Y_{n%2Bh}$%20in%20terms%20of%20${1,%20Y_1,%20...,%20Y_n}$%20for%20$n%20>%20k%20%2B%20l_3$,%20from%20recursions%20\begin{equation}%20P_n%20Y_{n%2Bh}%20=%20-%20\sum_{j%20=%201}^{k%20%2B%20l_3}%20\xi%20P_nY_{n%2Bh-j}%20%2B%20\phi(1)\bar{S},%20h\geq%201,%20\end{equation}%20with%20the%20initial%20conditions%20$P_n%20Y_{n%2Bh}%20=%20Y_{n%20%2B%20h}$,%20for%20$h\leq0$.%20)